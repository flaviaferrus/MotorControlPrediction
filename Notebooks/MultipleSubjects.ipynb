{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing custom functions from different folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/flaviaferrusmarimon/UB/MAM/TFM/Codes1/MotorControlPrediction/Implementation/utils_data\n",
      "/Users/flaviaferrusmarimon/UB/MAM/TFM/Codes1/MotorControlPrediction/Implementation\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "folder = 'Implementation'\n",
    "data_folder = os.path.join(parent_dir, folder)\n",
    "\n",
    "# Construct the full file path\n",
    "file_ = 'utils_data'\n",
    "full_path = os.path.join(data_folder, file_)\n",
    "print(full_path)\n",
    "print(data_folder)\n",
    "sys.path.append(data_folder)  \n",
    "\n",
    "# Load the functions from .py file  \n",
    "try:\n",
    "    from utils_data_multiple import load_multiple_data, plot_multiple_data, point_to_segment, cleaning_clustering_multiple_data\n",
    "    from utils_data_multiple import plot_data\n",
    "    from utils_data_multiple import saving_processed_mult_data, load_processed_mult_data, multiple_linear_transf  \n",
    "    from utils_model_multiple import load_params, fitParamaters_mult\n",
    "    #from utils_data import plot_velocity\n",
    "    #from utils_model_multiple import numericalSimulation, ComputeFunctional, ComputeVel\n",
    "    #from utils_model_multiple import generate_trajectory, plot_simulation, generate_trajectory_vel, optimize_Sigma, plot_multiple_trajectories, plotting_params\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"ModuleNotFoundError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating multiple subjects data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation may be: \n",
    "- 0: playing alone\n",
    "- 1: easy rival\n",
    "- 2: hard rival \n",
    "\n",
    "The data is now clustered by motivation level, i.e. `dataTrajecetories-25-M1-C1`. We are also splitting the dataset depending on the playing modes: passing through and stopping. For each dataset moreover we have the four different trajectories.\n",
    "\n",
    "The data is normalized, clustered in terms of motivation, playing mode and ordered by trajectory. \n",
    "\n",
    "We seek to find a paramater fitting for each subject, motivational state and playing mode, and trajectory. Then we can consider the mean for each case to fit the model for each subject and motivational state. \n",
    "\n",
    "We consider the mass to be the same at the begining of the movement, hence we are studying 3 motivational states x 2 playing modes parameters per player. \n",
    "\n",
    "We have 4 possible trajectories (the playing modes just modify the control function, since the effort is different). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reproduce our results in this Notebook by setting the initial parameters as well as on the `main_multiple.py` file. \n",
    "\n",
    "Set the following parameters according to the study you wish to conduct: \n",
    "- `processing` when set to `True` it conducts the whole processing process from the raw data. This includes: \n",
    "    - `cleaning_clustering_multiple_data`: \n",
    "        - Cleaning the trajectories which do not cross the target and truncating the ones which do cross it. Also storing the optimal time in which they reach the target, $T^*$, stored in `idxrule` \n",
    "        - Classifying the data in 4 clusters, depending on the target they cross\n",
    "    - `multiple_linear_transf`: \n",
    "        - Rotating the needed trajectories and scaling them in order to get normalized data\n",
    "        - Computing the mean velocity and the velocity profiles for each trajectory\n",
    "\n",
    "ATTENTION: This process takes more than 2 hours to be fully completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `fitting` when set to `True` the fitting of the parameters is conducted with the already processed data. This includes: \n",
    "    - `fitParamaters_mult`: \n",
    "        - Sequential approach: \n",
    "            1. Optimal movement duration: Generate the optimal trajectory by optimizing the Functional in terms of the time T \n",
    "            2. Optimal controller: generate the optimal trajectory with the optimal time duration by minimizing the functional in terms of the biomechanical parameters $(\\alpha, \\gamma, \\varepsilon)$. \n",
    "            3. Stochastic optimization: generate the optimal trajectory with optimal time duration and biomechanical parameters by optimizing the Kolmogorov Sirnov estimate in terms of the sigma \n",
    "        - Saving the obtained parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `plotting` when set to `True` all the trajectory plots and prints are explicitly shown on this Notebook\n",
    "- `saving` when set to `True` all the plots and data processed is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = False\n",
    "fitting = False\n",
    "plotting = False\n",
    "saving = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_points = [\n",
    "        (10.5, 4.85),   # pt2\n",
    "        (-11, -5),       # pt3  \n",
    "        (10.5, 0),      # pt1    \n",
    "        (-10.5, 1.25)  # pt0\n",
    "    ]\n",
    "n_clusters = 4\n",
    "\n",
    "segments = point_to_segment(cluster_points, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fitted parameters...\n",
      "Loading the new parameters...\n",
      "New parameters have been loaded successfully.\n",
      "Loading the new parameters...\n",
      "New parameters have been loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if processing:\n",
    "    print('Loading and processing data...')\n",
    "    data_dict = load_multiple_data(first_subj = 25, last_subj = 37, \n",
    "                       file_names = 'dataTrajectories' )\n",
    "    if plotting: \n",
    "        print('List with al the target segments:', segments)\n",
    "        print('List with the two points of segment for cluster 0:', segments[0])\n",
    "        print('Array with point target 1 for cluster 0:', segments[0][0])\n",
    "        print('First coordinate of point target 1 for cluster 0:', segments[0][0][0])\n",
    "        plot_multiple_data(data_dict)\n",
    "    \n",
    "    cleaned_data_dict, idxrule_dict = cleaning_clustering_multiple_data(data_dict, \n",
    "                                    segments, \n",
    "                                    first_subj = 25, last_subj = 37,\n",
    "                                    save_dir = 'subject_plots')\n",
    "\n",
    "    if saving: \n",
    "        saving_processed_mult_data(idxrule_dict=idxrule_dict, folder_name='clustered_multiple_data')\n",
    "        saving_processed_mult_data(cleaned_data_dict = cleaned_data_dict, \n",
    "                                folder_name = 'clustered_multiple_data')\n",
    "        \n",
    "    scaled_data_dict, velocity_dict, results_dict = multiple_linear_transf(cleaned_data_dict, idxrule_dict, \n",
    "                            segments, \n",
    "                            first_subj = 25, last_subj = 37,\n",
    "                            n_clusters = 4,\n",
    "                            saving = True, \n",
    "                            save_dir = 'subject_plots_2')\n",
    "    if saving: \n",
    "        saving_processed_mult_data(cleaned_data_dict = scaled_data_dict, \n",
    "                                folder_name = 'scaled_data')\n",
    "        saving_processed_mult_data(cleaned_data_dict = velocity_dict, \n",
    "                                folder_name = 'velocity')\n",
    "        saving_processed_mult_data(idxrule_dict = results_dict, \n",
    "                                folder_name = 'scaled_data')\n",
    "        \n",
    "    print('Fitting paramaters for the optimized trajectory...')   \n",
    "    \n",
    "    if fitting: \n",
    "        new_params, opt_sigma = fitParamaters_mult(scaled_data_dict,\n",
    "                    idxrule_dict, \n",
    "                    results_dict,\n",
    "                    segments, \n",
    "                    first_subj = 25, last_subj = 30,\n",
    "                    n_clusters = 4, folder_name = 'fitted_trajectories_2', \n",
    "                    saving = saving)\n",
    "    \n",
    "elif fitting: \n",
    "    print('Loading processed data...')\n",
    "    cleaned_data_dict, idxrule_dict = load_processed_mult_data(folder_name='clustered_multiple_data')\n",
    "    scaled_data_dict, results_dict = load_processed_mult_data(folder_name='scaled_multiple_data') \n",
    "    print('Data loaded and processed :)')\n",
    "    \n",
    "    print('Fitting paramaters for the optimized trajectory...')   \n",
    "    new_params, opt_sigma = fitParamaters_mult(scaled_data_dict,\n",
    "                  idxrule_dict, \n",
    "                  results_dict,\n",
    "                  segments, \n",
    "                  first_subj = 25, last_subj = 30,\n",
    "                  n_clusters = 4, folder_name = 'fitted_trajectories_2', \n",
    "                  saving = saving)\n",
    "    \n",
    "else: \n",
    "    print('Loading fitted parameters...')\n",
    "    params_loaded = load_params(folder_name = 'fitted_parameters')\n",
    "    opt_sigma = load_params(folder_name = 'fitted_parameters_sigma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([25, 31, 36, 30, 29, 27, 26, 28, 35, 32, 33, 34])\n",
      "dict_keys(['31_21_cluster_2', '31_12_cluster_1', '31_32_cluster_3', '31_32_cluster_2', '31_12_cluster_0', '31_21_cluster_3', '31_22_cluster_2', '31_31_cluster_3', '31_11_cluster_1', '31_11_cluster_0', '31_31_cluster_2', '31_22_cluster_3', '31_22_cluster_0', '31_11_cluster_3', '31_31_cluster_1', '31_31_cluster_0', '31_11_cluster_2', '31_22_cluster_1', '31_21_cluster_0', '31_32_cluster_1', '31_12_cluster_3', '31_12_cluster_2', '31_32_cluster_0', '31_21_cluster_1'])\n",
      "[ 2.94100671  3.03937839 -3.19640915]\n"
     ]
    }
   ],
   "source": [
    "print(params_loaded.keys())\n",
    "print(params_loaded[31].keys())\n",
    "print(params_loaded[31]['31_21_cluster_2'].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([25, 31, 36, 30, 29, 27, 26, 28, 35, 32, 33, 34])\n",
      "dict_keys(['28_32_cluster_3', '28_12_cluster_1', '28_21_cluster_2', '28_21_cluster_3', '28_12_cluster_0', '28_32_cluster_2', '28_11_cluster_1', '28_31_cluster_3', '28_22_cluster_2', '28_22_cluster_3', '28_31_cluster_2', '28_11_cluster_0', '28_31_cluster_1', '28_11_cluster_3', '28_22_cluster_0', '28_22_cluster_1', '28_11_cluster_2', '28_31_cluster_0', '28_12_cluster_3', '28_32_cluster_1', '28_21_cluster_0', '28_21_cluster_1', '28_32_cluster_0', '28_12_cluster_2'])\n",
      "5.07244087283925\n"
     ]
    }
   ],
   "source": [
    "print(opt_sigma.keys())\n",
    "print(opt_sigma[28].keys())\n",
    "print(opt_sigma[28]['28_32_cluster_3'].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
